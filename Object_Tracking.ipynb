{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbomiye/3mtt-data-science/blob/master/Object_Tracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFtdWtAxM-vp",
        "outputId": "8c4004e4-939c-4918-97bc-fe530353571d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.217-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.217-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.217 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2xWIEDSrhTLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ifzhang/ByteTrack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPwUiKfnT2hy",
        "outputId": "2da01685-1e57-49c9-bc8b-5c5b936145ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ByteTrack'...\n",
            "remote: Enumerating objects: 2007, done.\u001b[K\n",
            "remote: Total 2007 (delta 0), reused 0 (delta 0), pack-reused 2007 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2007/2007), 79.58 MiB | 30.69 MiB/s, done.\n",
            "Resolving deltas: 100% (1158/1158), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Download pretrained model ==\n",
        "\n",
        "%cd /content/ByteTrack/\n",
        "%mkdir pretrained\n",
        "%cd pretrained\n",
        "\n",
        "# == Download pretrained X model weights ==\n",
        "!gdown --id \"1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZVQFLeTAn7d",
        "outputId": "92f180e1-8d6c-446a-ecee-262c90440a05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ByteTrack\n",
            "/content/ByteTrack/pretrained\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\n",
            "From (redirected): https://drive.google.com/uc?id=1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5&confirm=t&uuid=a3899eca-6821-4316-98fa-d3c2ae86161b\n",
            "To: /content/ByteTrack/pretrained/bytetrack_x_mot17.pth.tar\n",
            "100% 793M/793M [00:12<00:00, 66.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Install dependencies ==\n",
        "!pip3 install cython\n",
        "!pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip3 install cython_bbox\n",
        "\n",
        "%cd /content/ByteTrack/\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPdB31iqBga_",
        "outputId": "d6f61402-8b8a-4c27-9870-e868fdb8762e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-_nccken6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-_nccken6\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (75.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.17.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp312-cp312-linux_x86_64.whl size=426680 sha256=9ae78f66a34cc6041dd5c35b6ef75c6d11c17950749d2e5f196971290942bf6a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-env31mvg/wheels/95/e6/c7/8ceda667bca7218619fea052622a0b11a37fb51c28c993fae3\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.10\n",
            "    Uninstalling pycocotools-2.0.10:\n",
            "      Successfully uninstalled pycocotools-2.0.10\n",
            "Successfully installed pycocotools-2.0\n",
            "Collecting cython_bbox\n",
            "  Downloading cython_bbox-0.1.5.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from cython_bbox) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cython_bbox) (2.0.2)\n",
            "Building wheels for collected packages: cython_bbox\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython_bbox: filename=cython_bbox-0.1.5-cp312-cp312-linux_x86_64.whl size=111559 sha256=67ce28d6503bdcf6f8a8a58c8d7314ff13795016252540da5f01e1e24689cb08\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e7/0a/7c310ac8921f2c1e61e58f80585f1ce0be9e4a36d280771857\n",
            "Successfully built cython_bbox\n",
            "Installing collected packages: cython_bbox\n",
            "Successfully installed cython_bbox-0.1.5\n",
            "/content/ByteTrack\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.8.0+cu126)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.12.0.88)\n",
            "Collecting loguru (from -r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.23.0+cu126)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Collecting thop (from -r requirements.txt (line 10))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ninja (from -r requirements.txt (line 11))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.19.0)\n",
            "Collecting lap (from -r requirements.txt (line 14))\n",
            "  Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting motmetrics (from -r requirements.txt (line 15))\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting filterpy (from -r requirements.txt (line 16))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (3.15.0)\n",
            "Collecting onnx==1.8.1 (from -r requirements.txt (line 20))\n",
            "  Downloading onnx-1.8.1.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime==1.8.0 (from versions: 1.17.0, 1.17.1, 1.17.3, 1.18.0, 1.18.1, 1.19.0, 1.19.2, 1.20.0, 1.20.1, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.23.0, 1.23.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Install ByteTrack ==\n",
        "!python3 setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzJ9_UlELnR",
        "outputId": "2283dc27-3fe4-4b67-8cee-4417a95f6ff4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating yolox.egg-info\n",
            "writing yolox.egg-info/PKG-INFO\n",
            "writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "writing top-level names to yolox.egg-info/top_level.txt\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "W1019 18:34:37.597000 1911 torch/utils/cpp_extension.py:615] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "reading manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'yolox._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.12/dist-packages/torch/include -I/usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -I/usr/include/python3.12 -c /content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.cpp -o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=_C -std=c++17\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.12/dist-packages/torch/include -I/usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -I/usr/include/python3.12 -c /content/ByteTrack/yolox/layers/csrc/vision.cpp -o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=_C -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-312/yolox\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/vision.o -L/usr/local/lib/python3.12/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-312/yolox/_C.cpython-312-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-312/yolox/_C.cpython-312-x86_64-linux-gnu.so -> yolox\n",
            "Creating /usr/local/lib/python3.12/dist-packages/yolox.egg-link (link to .)\n",
            "Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/ByteTrack\n",
            "Processing dependencies for yolox==0.1.0\n",
            "Finished processing dependencies for yolox==0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install loguru sap lap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn0StpdLWLY-",
        "outputId": "19aa3f10-db97-4c8d-87a6-ad9f8cf4ff82"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting sap\n",
            "  Downloading sap-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting lap\n",
            "  Using cached lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sap) (2.0.2)\n",
            "Collecting higra (from sap)\n",
            "  Downloading higra-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sap) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from sap) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->sap) (1.17.0)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sap-1.0.0-py3-none-any.whl (31 kB)\n",
            "Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading higra-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru, lap, higra, sap\n",
            "Successfully installed higra-0.6.12 lap-0.5.12 loguru-0.7.3 sap-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demo\n",
        "# fix np.float32 and replace with float\n",
        "%cd /content/ByteTrack/\n",
        "!python3 tools/demo_track.py video -f exps/example/mot/yolox_x_mix_det.py -c pretrained/bytetrack_x_mot17.pth.tar --fp16 --fuse --save_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwXXu4vm9jmp",
        "outputId": "86bce9a2-40be-4a3f-9527-57c1e440e7ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ByteTrack\n",
            "\u001b[32m2025-10-19 18:35:20.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mArgs: Namespace(demo='video', experiment_name='yolox_x_mix_det', name=None, path='./videos/palace.mp4', camid=0, save_result=True, exp_file='exps/example/mot/yolox_x_mix_det.py', ckpt='pretrained/bytetrack_x_mot17.pth.tar', device=device(type='cuda'), conf=None, nms=None, tsize=None, fps=30, fp16=True, fuse=True, trt=False, track_thresh=0.5, track_buffer=30, match_thresh=0.8, aspect_ratio_thresh=1.6, min_box_area=10, mot20=False)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m2025-10-19 18:35:22.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mModel Summary: Params: 99.00M, Gflops: 793.21\u001b[0m\n",
            "\u001b[32m2025-10-19 18:35:22.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "\u001b[32m2025-10-19 18:35:23.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n",
            "\u001b[32m2025-10-19 18:35:23.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m341\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:967: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  param_grad = param.grad\n",
            "\u001b[32m2025-10-19 18:35:24.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x_mix_det/track_vis/2025_10_19_18_35_24/palace.mp4\u001b[0m\n",
            "\u001b[32m2025-10-19 18:35:24.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 372, in <module>\n",
            "    main(exp, args)\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 365, in main\n",
            "    imageflow_demo(predictor, vis_folder, current_time, args)\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 263, in imageflow_demo\n",
            "    online_targets = tracker.update(outputs[0], [img_info['height'], img_info['width']], exp.test_size)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ByteTrack/yolox/tracker/byte_tracker.py\", line 189, in update\n",
            "    detections = [STrack(STrack.tlbr_to_tlwh(tlbr), s) for\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ByteTrack/yolox/tracker/byte_tracker.py\", line 18, in __init__\n",
            "    self._tlwh = np.asarray(tlwh, dtype=np.float)\n",
            "                                        ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\", line 394, in __getattr__\n",
            "    raise AttributeError(__former_attrs__[attr])\n",
            "AttributeError: module 'numpy' has no attribute 'float'.\n",
            "`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
            "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'float16'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "asbqiSCW90hX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEweWKyPAm8Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3nMdJuje90po"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OPkeTtb90uk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0SCic3590x-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTBef2AAZEam",
        "outputId": "f770b376-4ef3-4beb-c916-00d227b2022f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the model\n",
        "yolo = YOLO('yolov5s.pt')\n",
        "\n",
        "# Load the video capture\n",
        "videoCap = cv2.VideoCapture(\"/content/ByteTrack/videos/palace.mp4\")\n",
        "width = int(videoCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(videoCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = videoCap.get(cv2.CAP_PROP_FPS)\n",
        "num_frames =int(videoCap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "video_writer = cv2.VideoWriter('./output.avi', fourcc , fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48KQ5Br8VlIA",
        "outputId": "7d458fdf-84bd-476e-95c9-26037498446e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17.7MB 138.2MB/s 0.1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to get class colors\n",
        "def getColours(cls_num):\n",
        "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "    color_index = cls_num % len(base_colors)\n",
        "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
        "    color = [base_colors[color_index][i] + increments[color_index][i] *\n",
        "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
        "    return tuple(color)\n",
        "\n",
        "\n",
        "# while True:\n",
        "for frame_i in tqdm(range(num_frames+2)):\n",
        "\n",
        "    ret, frame = videoCap.read()\n",
        "    if not ret:\n",
        "        continue\n",
        "    results = yolo.track(frame, tracker='bytetrack.yaml')\n",
        "\n",
        "    for result in results:\n",
        "        # get the classes names and object id\n",
        "        classes_names = result.names\n",
        "\n",
        "        boxes = results[0].boxes.xyxy.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "        box_classes = results[0].boxes.cls.int().cpu().tolist()\n",
        "\n",
        "\n",
        "        # iterate over each box\n",
        "        for box, tid, cls in zip(boxes, track_ids, box_classes):\n",
        "\n",
        "            # get coordinates\n",
        "            [x1, y1, x2, y2] = box\n",
        "            # convert to int\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            # get the class\n",
        "            cls = int(cls)\n",
        "\n",
        "            # get the class name\n",
        "            class_name = classes_names[cls]\n",
        "\n",
        "            # get the respective colour\n",
        "            colour = getColours(cls)\n",
        "\n",
        "            # draw the rectangle\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
        "\n",
        "            # put the class name and confidence on the image\n",
        "            cv2.putText(frame, f'{classes_names[cls]} {tid}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
        "\n",
        "    # show the image\n",
        "    # cv2_imshow('frame', frame)\n",
        "    video_writer.write(frame)\n",
        "\n",
        "    # break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# release the video capture and destroy all windows\n",
        "videoCap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh1KL4onZ5mE",
        "outputId": "9b3ebf70-e214-4e58-a1d8-aef0eed0c552"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/331 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 8 handbags, 1 suitcase, 74.8ms\n",
            "Speed: 10.6ms preprocess, 74.8ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/331 [00:02<12:58,  2.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 5 handbags, 2 suitcases, 17.3ms\n",
            "Speed: 9.8ms preprocess, 17.3ms inference, 23.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 2/331 [00:02<05:41,  1.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 30.5ms\n",
            "Speed: 4.0ms preprocess, 30.5ms inference, 32.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/331 [00:02<03:26,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 42.4ms\n",
            "Speed: 8.0ms preprocess, 42.4ms inference, 55.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 4/331 [00:02<02:25,  2.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 20.4ms\n",
            "Speed: 6.4ms preprocess, 20.4ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6 handbags, 1 suitcase, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|‚ñè         | 6/331 [00:02<01:22,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 7 handbags, 22.8ms\n",
            "Speed: 6.0ms preprocess, 22.8ms inference, 38.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|‚ñè         | 7/331 [00:03<01:13,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 7 handbags, 23.2ms\n",
            "Speed: 8.5ms preprocess, 23.2ms inference, 31.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|‚ñè         | 8/331 [00:03<01:02,  5.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 6 handbags, 21.1ms\n",
            "Speed: 7.5ms preprocess, 21.1ms inference, 46.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|‚ñé         | 9/331 [00:03<00:55,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 6 handbags, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 handbags, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|‚ñé         | 11/331 [00:03<00:43,  7.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 6 handbags, 20.0ms\n",
            "Speed: 5.1ms preprocess, 20.0ms inference, 27.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|‚ñé         | 12/331 [00:03<00:42,  7.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 5 handbags, 21.8ms\n",
            "Speed: 4.0ms preprocess, 21.8ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 31.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|‚ñç         | 14/331 [00:03<00:38,  8.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 6 handbags, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6 handbags, 21.5ms\n",
            "Speed: 9.2ms preprocess, 21.5ms inference, 50.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|‚ñç         | 16/331 [00:04<00:37,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 55.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|‚ñå         | 17/331 [00:04<00:38,  8.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 23.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 26.9ms\n",
            "Speed: 3.7ms preprocess, 26.9ms inference, 48.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|‚ñå         | 19/331 [00:04<00:35,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 29.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 22.6ms\n",
            "Speed: 2.1ms preprocess, 22.6ms inference, 27.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|‚ñã         | 21/331 [00:04<00:32,  9.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 23.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 28.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|‚ñã         | 23/331 [00:04<00:30, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 25.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 backpacks, 5 handbags, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 25.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|‚ñä         | 25/331 [00:04<00:27, 11.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 car, 3 backpacks, 6 handbags, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 5 handbags, 10.9ms\n",
            "Speed: 6.0ms preprocess, 10.9ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|‚ñä         | 27/331 [00:05<00:27, 11.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 2 backpacks, 5 handbags, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 5 handbags, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 59.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|‚ñâ         | 29/331 [00:05<00:28, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 2 backpacks, 3 handbags, 28.4ms\n",
            "Speed: 5.1ms preprocess, 28.4ms inference, 47.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 3 handbags, 13.3ms\n",
            "Speed: 6.0ms preprocess, 13.3ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|‚ñâ         | 31/331 [00:05<00:29, 10.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 50.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 1 umbrella, 4 handbags, 32.7ms\n",
            "Speed: 10.3ms preprocess, 32.7ms inference, 65.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|‚ñâ         | 33/331 [00:05<00:36,  8.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 umbrella, 3 handbags, 1 suitcase, 19.3ms\n",
            "Speed: 9.2ms preprocess, 19.3ms inference, 28.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|‚ñà         | 34/331 [00:05<00:35,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 29.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|‚ñà         | 36/331 [00:06<00:30,  9.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 1 skateboard, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|‚ñà‚ñè        | 38/331 [00:06<00:26, 11.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|‚ñà‚ñè        | 40/331 [00:06<00:24, 11.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.8ms preprocess, 10.0ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|‚ñà‚ñé        | 42/331 [00:06<00:22, 12.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 8 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|‚ñà‚ñé        | 44/331 [00:06<00:22, 12.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 2 suitcases, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7 handbags, 2 suitcases, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 23.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|‚ñà‚ñç        | 46/331 [00:06<00:21, 13.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 2 suitcases, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 24.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 fire hydrant, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|‚ñà‚ñç        | 48/331 [00:06<00:20, 13.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 fire hydrant, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 fire hydrant, 1 backpack, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|‚ñà‚ñå        | 50/331 [00:07<00:19, 14.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 6 handbags, 11.5ms\n",
            "Speed: 3.9ms preprocess, 11.5ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|‚ñà‚ñå        | 52/331 [00:07<00:18, 14.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|‚ñà‚ñã        | 54/331 [00:07<00:18, 15.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 13.2ms\n",
            "Speed: 3.9ms preprocess, 13.2ms inference, 23.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 13.2ms\n",
            "Speed: 1.9ms preprocess, 13.2ms inference, 25.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|‚ñà‚ñã        | 56/331 [00:07<00:19, 14.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 11.6ms\n",
            "Speed: 1.9ms preprocess, 11.6ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 8 handbags, 10.6ms\n",
            "Speed: 4.5ms preprocess, 10.6ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|‚ñà‚ñä        | 58/331 [00:07<00:18, 14.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 backpack, 6 handbags, 1 bottle, 22.3ms\n",
            "Speed: 1.8ms preprocess, 22.3ms inference, 32.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|‚ñà‚ñä        | 60/331 [00:07<00:19, 13.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 23.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 26.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|‚ñà‚ñä        | 62/331 [00:07<00:19, 13.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 26.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 12.4ms\n",
            "Speed: 3.9ms preprocess, 12.4ms inference, 25.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|‚ñà‚ñâ        | 64/331 [00:08<00:20, 13.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 13.5ms\n",
            "Speed: 2.5ms preprocess, 13.5ms inference, 25.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|‚ñà‚ñâ        | 66/331 [00:08<00:19, 13.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|‚ñà‚ñà        | 68/331 [00:08<00:17, 15.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|‚ñà‚ñà        | 70/331 [00:08<00:16, 16.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|‚ñà‚ñà‚ñè       | 72/331 [00:08<00:15, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|‚ñà‚ñà‚ñè       | 74/331 [00:08<00:14, 17.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 4 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 20.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|‚ñà‚ñà‚ñé       | 76/331 [00:08<00:14, 17.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 4 backpacks, 4 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|‚ñà‚ñà‚ñé       | 78/331 [00:08<00:14, 17.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 6 handbags, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 23.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 6 handbags, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|‚ñà‚ñà‚ñç       | 80/331 [00:08<00:14, 17.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|‚ñà‚ñà‚ñç       | 82/331 [00:09<00:13, 18.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|‚ñà‚ñà‚ñå       | 84/331 [00:09<00:13, 18.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|‚ñà‚ñà‚ñå       | 86/331 [00:09<00:13, 18.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 8 handbags, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|‚ñà‚ñà‚ñã       | 88/331 [00:09<00:13, 18.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 6 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 backpacks, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|‚ñà‚ñà‚ñã       | 90/331 [00:09<00:12, 18.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|‚ñà‚ñà‚ñä       | 92/331 [00:09<00:12, 19.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.4ms\n",
            "Speed: 2.4ms preprocess, 10.4ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|‚ñà‚ñà‚ñä       | 95/331 [00:09<00:12, 19.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|‚ñà‚ñà‚ñâ       | 98/331 [00:09<00:11, 20.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|‚ñà‚ñà‚ñà       | 101/331 [00:10<00:11, 19.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|‚ñà‚ñà‚ñà       | 103/331 [00:10<00:11, 19.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|‚ñà‚ñà‚ñà‚ñè      | 105/331 [00:10<00:11, 19.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|‚ñà‚ñà‚ñà‚ñé      | 108/331 [00:10<00:10, 20.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|‚ñà‚ñà‚ñà‚ñé      | 111/331 [00:10<00:10, 20.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|‚ñà‚ñà‚ñà‚ñç      | 114/331 [00:10<00:10, 20.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|‚ñà‚ñà‚ñà‚ñå      | 117/331 [00:10<00:10, 20.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 2 suitcases, 12.7ms\n",
            "Speed: 3.8ms preprocess, 12.7ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|‚ñà‚ñà‚ñà‚ñã      | 120/331 [00:10<00:10, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 suitcase, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|‚ñà‚ñà‚ñà‚ñã      | 122/331 [00:11<00:10, 19.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|‚ñà‚ñà‚ñà‚ñã      | 124/331 [00:11<00:10, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|‚ñà‚ñà‚ñà‚ñä      | 126/331 [00:11<00:10, 19.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|‚ñà‚ñà‚ñà‚ñä      | 128/331 [00:11<00:10, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|‚ñà‚ñà‚ñà‚ñâ      | 130/331 [00:11<00:10, 19.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|‚ñà‚ñà‚ñà‚ñà      | 133/331 [00:11<00:09, 20.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|‚ñà‚ñà‚ñà‚ñà      | 136/331 [00:11<00:09, 20.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 139/331 [00:11<00:09, 20.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 handbags, 1 suitcase, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 handbags, 1 suitcase, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 142/331 [00:12<00:09, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 145/331 [00:12<00:09, 20.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 13.1ms\n",
            "Speed: 2.0ms preprocess, 13.1ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 148/331 [00:12<00:08, 20.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 151/331 [00:12<00:08, 20.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 154/331 [00:12<00:08, 20.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 157/331 [00:12<00:08, 20.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 160/331 [00:12<00:08, 21.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 163/331 [00:13<00:08, 20.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 166/331 [00:13<00:07, 21.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 9 persons, 4 handbags, 1 suitcase, 14.6ms\n",
            "Speed: 2.5ms preprocess, 14.6ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 169/331 [00:13<00:07, 20.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 172/331 [00:13<00:07, 20.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 175/331 [00:13<00:07, 20.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 horse, 1 backpack, 2 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 19.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 horse, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 horse, 1 backpack, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 178/331 [00:13<00:07, 20.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 181/331 [00:13<00:07, 19.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 4 handbags, 1 suitcase, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 183/331 [00:14<00:07, 19.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 185/331 [00:14<00:07, 19.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 188/331 [00:14<00:07, 19.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 191/331 [00:14<00:06, 20.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 3 handbags, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 194/331 [00:14<00:06, 20.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 197/331 [00:14<00:06, 20.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 200/331 [00:14<00:06, 20.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 handbags, 2 suitcases, 12.5ms\n",
            "Speed: 1.9ms preprocess, 12.5ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 203/331 [00:15<00:06, 20.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 206/331 [00:15<00:06, 20.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 209/331 [00:15<00:06, 19.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 212/331 [00:15<00:06, 19.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.9ms preprocess, 9.9ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 214/331 [00:15<00:05, 19.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 17 persons, 4 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.5ms preprocess, 9.9ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 216/331 [00:15<00:05, 19.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 218/331 [00:15<00:05, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 221/331 [00:15<00:05, 19.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 17 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 223/331 [00:16<00:05, 19.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 suitcases, 12.7ms\n",
            "Speed: 3.9ms preprocess, 12.7ms inference, 23.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 suitcases, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 225/331 [00:16<00:05, 18.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 5 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 227/331 [00:16<00:05, 18.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 5.4ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 229/331 [00:16<00:05, 18.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 21.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 232/331 [00:16<00:05, 18.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 234/331 [00:16<00:05, 18.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 236/331 [00:16<00:05, 18.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 239/331 [00:16<00:04, 19.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 242/331 [00:17<00:04, 19.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 244/331 [00:17<00:04, 19.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 2 suitcases, 11.3ms\n",
            "Speed: 1.9ms preprocess, 11.3ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 246/331 [00:17<00:04, 19.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 4 handbags, 1 suitcase, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 248/331 [00:17<00:04, 19.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 250/331 [00:17<00:04, 18.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 252/331 [00:17<00:04, 18.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 7 handbags, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 1 suitcase, 10.4ms\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 254/331 [00:17<00:04, 18.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 256/331 [00:17<00:03, 18.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 258/331 [00:17<00:03, 19.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 4.0ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 260/331 [00:18<00:03, 18.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 262/331 [00:18<00:03, 19.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 16.1ms\n",
            "Speed: 4.0ms preprocess, 16.1ms inference, 37.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 20.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 264/331 [00:18<00:04, 16.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 266/331 [00:18<00:03, 16.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 12.1ms\n",
            "Speed: 3.9ms preprocess, 12.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 268/331 [00:18<00:03, 16.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 10.2ms\n",
            "Speed: 4.1ms preprocess, 10.2ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 19.3ms\n",
            "Speed: 1.8ms preprocess, 19.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 270/331 [00:18<00:03, 15.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.9ms\n",
            "Speed: 4.5ms preprocess, 10.9ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 272/331 [00:18<00:03, 15.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 6 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 274/331 [00:18<00:03, 15.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.8ms preprocess, 10.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.7ms\n",
            "Speed: 1.7ms preprocess, 10.7ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 276/331 [00:19<00:03, 15.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 suitcase, 11.3ms\n",
            "Speed: 4.4ms preprocess, 11.3ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 278/331 [00:19<00:03, 15.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.8ms preprocess, 10.0ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 15.0ms\n",
            "Speed: 2.4ms preprocess, 15.0ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 280/331 [00:19<00:03, 15.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 282/331 [00:19<00:03, 16.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 2 suitcases, 1 bottle, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 11.6ms\n",
            "Speed: 1.8ms preprocess, 11.6ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 284/331 [00:19<00:02, 16.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 2 suitcases, 1 cell phone, 13.5ms\n",
            "Speed: 6.0ms preprocess, 13.5ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 25.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 286/331 [00:19<00:02, 15.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.4ms\n",
            "Speed: 6.7ms preprocess, 10.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 1 suitcase, 12.2ms\n",
            "Speed: 1.9ms preprocess, 12.2ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 288/331 [00:19<00:02, 15.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 290/331 [00:20<00:02, 14.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 2 handbags, 1 suitcase, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 292/331 [00:20<00:02, 14.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 11.5ms\n",
            "Speed: 4.5ms preprocess, 11.5ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 294/331 [00:20<00:02, 14.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 18.2ms\n",
            "Speed: 2.3ms preprocess, 18.2ms inference, 24.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 14.5ms\n",
            "Speed: 4.7ms preprocess, 14.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 296/331 [00:20<00:02, 14.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 handbag, 1 suitcase, 15.6ms\n",
            "Speed: 2.4ms preprocess, 15.6ms inference, 27.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 cell phone, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 298/331 [00:20<00:02, 13.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 10 persons, 1 backpack, 2 handbags, 1 cell phone, 11.9ms\n",
            "Speed: 5.5ms preprocess, 11.9ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 18.3ms\n",
            "Speed: 4.0ms preprocess, 18.3ms inference, 27.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 300/331 [00:20<00:02, 13.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 13.0ms\n",
            "Speed: 2.7ms preprocess, 13.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 302/331 [00:20<00:01, 14.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 305/331 [00:20<00:01, 16.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 9.9ms\n",
            "Speed: 1.8ms preprocess, 9.9ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 2 handbags, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 308/331 [00:21<00:01, 17.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 311/331 [00:21<00:01, 18.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 10 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 313/331 [00:21<00:00, 19.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 8 persons, 2 backpacks, 3 handbags, 1 suitcase, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 315/331 [00:21<00:00, 18.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 8 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 318/331 [00:21<00:00, 19.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 3 handbags, 1 suitcase, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 320/331 [00:21<00:00, 19.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 2 handbags, 1 suitcase, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 323/331 [00:21<00:00, 19.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 suitcase, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 handbag, 2 suitcases, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 325/331 [00:21<00:00, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 327/331 [00:22<00:00, 19.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 331/331 [00:22<00:00, 14.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iax_ZdK-L-Q1"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}