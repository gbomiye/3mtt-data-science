{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbomiye/3mtt-data-science/blob/master/Object_Video_Track.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFtdWtAxM-vp",
        "outputId": "f1f65f4f-1d33-46f7-ef36-bb864bccf4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.217-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.217-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.217 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip3 install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2xWIEDSrhTLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ifzhang/ByteTrack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPwUiKfnT2hy",
        "outputId": "a62cb3f2-c807-4221-e14d-8b82176da247"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ByteTrack'...\n",
            "remote: Enumerating objects: 2007, done.\u001b[K\n",
            "remote: Total 2007 (delta 0), reused 0 (delta 0), pack-reused 2007 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2007/2007), 79.58 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (1158/1158), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Download pretrained model ==\n",
        "\n",
        "%cd /content/ByteTrack/\n",
        "%mkdir pretrained\n",
        "%cd pretrained\n",
        "\n",
        "# == Download pretrained X model weights ==\n",
        "!gdown --id \"1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZVQFLeTAn7d",
        "outputId": "eb839ee2-6e8e-48f2-b00a-c35849c88863"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ByteTrack\n",
            "/content/ByteTrack/pretrained\n",
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5\n",
            "From (redirected): https://drive.google.com/uc?id=1P4mY0Yyd3PPTybgZkjMYhFri88nTmJX5&confirm=t&uuid=445dfa83-0bd7-4862-885a-3fb8c8551c24\n",
            "To: /content/ByteTrack/pretrained/bytetrack_x_mot17.pth.tar\n",
            "100% 793M/793M [00:15<00:00, 51.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Install dependencies ==\n",
        "!pip3 install cython\n",
        "!pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!pip3 install cython_bbox\n",
        "\n",
        "%cd /content/ByteTrack/\n",
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPdB31iqBga_",
        "outputId": "85079891-9981-4afd-bc84-e3488cf067c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-4eldwyla\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-4eldwyla\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (75.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.17.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp312-cp312-linux_x86_64.whl size=426675 sha256=18a2a18539801f0ac0cb7323dddf0e48a4509ca60a9628834b7a56f6f15a04b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xuqjkybt/wheels/95/e6/c7/8ceda667bca7218619fea052622a0b11a37fb51c28c993fae3\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.10\n",
            "    Uninstalling pycocotools-2.0.10:\n",
            "      Successfully uninstalled pycocotools-2.0.10\n",
            "Successfully installed pycocotools-2.0\n",
            "Collecting cython_bbox\n",
            "  Downloading cython_bbox-0.1.5.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from cython_bbox) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cython_bbox) (2.0.2)\n",
            "Building wheels for collected packages: cython_bbox\n",
            "  Building wheel for cython_bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython_bbox: filename=cython_bbox-0.1.5-cp312-cp312-linux_x86_64.whl size=111563 sha256=aca12f39b1aadf272b1244bbb1329c1b23c0355c935d1b0c8cfd91baca6ff1ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/e7/0a/7c310ac8921f2c1e61e58f80585f1ce0be9e4a36d280771857\n",
            "Successfully built cython_bbox\n",
            "Installing collected packages: cython_bbox\n",
            "Successfully installed cython_bbox-0.1.5\n",
            "/content/ByteTrack\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.8.0+cu126)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (4.12.0.88)\n",
            "Collecting loguru (from -r requirements.txt (line 5))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.23.0+cu126)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Collecting thop (from -r requirements.txt (line 10))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting ninja (from -r requirements.txt (line 11))\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.9.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.19.0)\n",
            "Collecting lap (from -r requirements.txt (line 14))\n",
            "  Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting motmetrics (from -r requirements.txt (line 15))\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting filterpy (from -r requirements.txt (line 16))\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (3.15.0)\n",
            "Collecting onnx==1.8.1 (from -r requirements.txt (line 20))\n",
            "  Downloading onnx-1.8.1.tar.gz (5.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement onnxruntime==1.8.0 (from versions: 1.17.0, 1.17.1, 1.17.3, 1.18.0, 1.18.1, 1.19.0, 1.19.2, 1.20.0, 1.20.1, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.23.0, 1.23.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for onnxruntime==1.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == Install ByteTrack ==\n",
        "!python3 setup.py develop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzJ9_UlELnR",
        "outputId": "faad4149-4d6c-499a-ac20-e1e895566f49"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating yolox.egg-info\n",
            "writing yolox.egg-info/PKG-INFO\n",
            "writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "writing top-level names to yolox.egg-info/top_level.txt\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "W1019 01:34:52.219000 1274 torch/utils/cpp_extension.py:615] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "reading manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'yolox._C' extension\n",
            "creating build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.12/dist-packages/torch/include -I/usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -I/usr/include/python3.12 -c /content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.cpp -o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=_C -std=c++17\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/ByteTrack/yolox/layers/csrc -I/usr/local/lib/python3.12/dist-packages/torch/include -I/usr/local/lib/python3.12/dist-packages/torch/include/torch/csrc/api/include -I/usr/include/python3.12 -c /content/ByteTrack/yolox/layers/csrc/vision.cpp -o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1018\\\" -DTORCH_EXTENSION_NAME=_C -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-312/yolox\n",
            "x86_64-linux-gnu-g++ -fno-strict-overflow -Wsign-compare -DNDEBUG -g -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/cocoeval/cocoeval.o build/temp.linux-x86_64-cpython-312/content/ByteTrack/yolox/layers/csrc/vision.o -L/usr/local/lib/python3.12/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-312/yolox/_C.cpython-312-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-cpython-312/yolox/_C.cpython-312-x86_64-linux-gnu.so -> yolox\n",
            "Creating /usr/local/lib/python3.12/dist-packages/yolox.egg-link (link to .)\n",
            "Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /content/ByteTrack\n",
            "Processing dependencies for yolox==0.1.0\n",
            "Finished processing dependencies for yolox==0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install loguru sap lap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn0StpdLWLY-",
        "outputId": "cd58fd20-4f48-4b5b-d5a9-6f546619cb4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting loguru\n",
            "  Using cached loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting sap\n",
            "  Downloading sap-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting lap\n",
            "  Using cached lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sap) (2.0.2)\n",
            "Collecting higra (from sap)\n",
            "  Downloading higra-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sap) (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from sap) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->sap) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->sap) (1.17.0)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sap-1.0.0-py3-none-any.whl (31 kB)\n",
            "Downloading lap-0.5.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading higra-0.6.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: loguru, lap, higra, sap\n",
            "Successfully installed higra-0.6.12 lap-0.5.12 loguru-0.7.3 sap-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demo\n",
        "# fix np.float32 and replace with float\n",
        "%cd /content/ByteTrack/\n",
        "!python3 tools/demo_track.py video -f exps/example/mot/yolox_x_mix_det.py -c pretrained/bytetrack_x_mot17.pth.tar --fp16 --fuse --save_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwXXu4vm9jmp",
        "outputId": "d3da1912-446d-46e0-ae6f-91db88fbdfa6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ByteTrack\n",
            "\u001b[32m2025-10-19 01:35:48.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m316\u001b[0m - \u001b[1mArgs: Namespace(demo='video', experiment_name='yolox_x_mix_det', name=None, path='./videos/palace.mp4', camid=0, save_result=True, exp_file='exps/example/mot/yolox_x_mix_det.py', ckpt='pretrained/bytetrack_x_mot17.pth.tar', device=device(type='cuda'), conf=None, nms=None, tsize=None, fps=30, fp16=True, fuse=True, trt=False, track_thresh=0.5, track_buffer=30, match_thresh=0.8, aspect_ratio_thresh=1.6, min_box_area=10, mot20=False)\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4322.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "\u001b[32m2025-10-19 01:35:51.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m326\u001b[0m - \u001b[1mModel Summary: Params: 99.00M, Gflops: 793.21\u001b[0m\n",
            "\u001b[32m2025-10-19 01:35:51.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "\u001b[32m2025-10-19 01:35:52.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m338\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n",
            "\u001b[32m2025-10-19 01:35:52.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m341\u001b[0m - \u001b[1m\tFusing model...\u001b[0m\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:967: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
            "  param_grad = param.grad\n",
            "\u001b[32m2025-10-19 01:35:53.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m248\u001b[0m - \u001b[1mvideo save_path is ./YOLOX_outputs/yolox_x_mix_det/track_vis/2025_10_19_01_35_53/palace.mp4\u001b[0m\n",
            "\u001b[32m2025-10-19 01:35:53.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mimageflow_demo\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mProcessing frame 0 (100000.00 fps)\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 372, in <module>\n",
            "    main(exp, args)\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 365, in main\n",
            "    imageflow_demo(predictor, vis_folder, current_time, args)\n",
            "  File \"/content/ByteTrack/tools/demo_track.py\", line 263, in imageflow_demo\n",
            "    online_targets = tracker.update(outputs[0], [img_info['height'], img_info['width']], exp.test_size)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ByteTrack/yolox/tracker/byte_tracker.py\", line 189, in update\n",
            "    detections = [STrack(STrack.tlbr_to_tlwh(tlbr), s) for\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ByteTrack/yolox/tracker/byte_tracker.py\", line 18, in __init__\n",
            "    self._tlwh = np.asarray(tlwh, dtype=np.float)\n",
            "                                        ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\", line 394, in __getattr__\n",
            "    raise AttributeError(__former_attrs__[attr])\n",
            "AttributeError: module 'numpy' has no attribute 'float'.\n",
            "`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
            "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'float16'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTBef2AAZEam",
        "outputId": "540dfdbc-06ee-4886-85d7-41fc0fd176f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the model\n",
        "yolo = YOLO('yolov5s.pt')\n",
        "\n",
        "# Load the video capture\n",
        "videoCap = cv2.VideoCapture(\"/content/ByteTrack/videos/palace.mp4\")\n",
        "width = int(videoCap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(videoCap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "frames_per_second = videoCap.get(cv2.CAP_PROP_FPS)\n",
        "num_frames =int(videoCap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "video_writer = cv2.VideoWriter('./output.avi', fourcc , fps=float(frames_per_second), frameSize=(width, height), isColor=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48KQ5Br8VlIA",
        "outputId": "93543491-51aa-4d21-90d8-e9e85c76783b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 17.7MB 83.8MB/s 0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to get class colors\n",
        "def getColours(cls_num):\n",
        "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "    color_index = cls_num % len(base_colors)\n",
        "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
        "    color = [base_colors[color_index][i] + increments[color_index][i] *\n",
        "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
        "    return tuple(color)\n",
        "\n",
        "\n",
        "# while True:\n",
        "for frame_i in tqdm(range(num_frames+2)):\n",
        "\n",
        "    ret, frame = videoCap.read()\n",
        "    if not ret:\n",
        "        continue\n",
        "    results = yolo.track(frame, tracker='bytetrack.yaml')\n",
        "\n",
        "    for result in results:\n",
        "        # get the classes names and object id\n",
        "        classes_names = result.names\n",
        "\n",
        "        boxes = results[0].boxes.xyxy.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "        box_classes = results[0].boxes.cls.int().cpu().tolist()\n",
        "\n",
        "\n",
        "        # iterate over each box\n",
        "        for box, tid, cls in zip(boxes, track_ids, box_classes):\n",
        "\n",
        "            # get coordinates\n",
        "            [x1, y1, x2, y2] = box\n",
        "            # convert to int\n",
        "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "            # get the class\n",
        "            cls = int(cls)\n",
        "\n",
        "            # get the class name\n",
        "            class_name = classes_names[cls]\n",
        "\n",
        "            # get the respective colour\n",
        "            colour = getColours(cls)\n",
        "\n",
        "            # draw the rectangle\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
        "\n",
        "            # put the class name and confidence on the image\n",
        "            cv2.putText(frame, f'{classes_names[cls]} {tid}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
        "\n",
        "    # show the image\n",
        "    # cv2_imshow('frame', frame)\n",
        "    video_writer.write(frame)\n",
        "\n",
        "    # break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# release the video capture and destroy all windows\n",
        "videoCap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh1KL4onZ5mE",
        "outputId": "c1780b99-82bf-40ba-d268-1474f62ca26e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/331 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 8 handbags, 1 suitcase, 43.9ms\n",
            "Speed: 9.2ms preprocess, 43.9ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/331 [00:01<05:57,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 3/331 [00:01<01:45,  3.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 6 handbags, 1 suitcase, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|‚ñè         | 6/331 [00:01<00:50,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 7 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 7 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|‚ñé         | 9/331 [00:01<00:33,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 5 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|‚ñé         | 12/331 [00:01<00:26, 12.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 5 handbags, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|‚ñç         | 14/331 [00:01<00:23, 13.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 6 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|‚ñå         | 17/331 [00:01<00:20, 15.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|‚ñå         | 20/331 [00:02<00:18, 17.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|‚ñã         | 22/331 [00:02<00:17, 17.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|‚ñã         | 24/331 [00:02<00:17, 17.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 3 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 3 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|‚ñä         | 26/331 [00:02<00:16, 18.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|‚ñä         | 28/331 [00:02<00:16, 18.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 3 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 2 backpacks, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|‚ñâ         | 30/331 [00:02<00:16, 18.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|‚ñâ         | 32/331 [00:02<00:16, 18.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 car, 1 backpack, 1 umbrella, 4 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 umbrella, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|‚ñà         | 34/331 [00:02<00:15, 18.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|‚ñà         | 36/331 [00:02<00:15, 19.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 1 skateboard, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|‚ñà‚ñè        | 38/331 [00:02<00:15, 19.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|‚ñà‚ñè        | 40/331 [00:03<00:14, 19.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 8 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 21.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|‚ñà‚ñé        | 43/331 [00:03<00:15, 19.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|‚ñà‚ñé        | 45/331 [00:03<00:14, 19.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|‚ñà‚ñç        | 47/331 [00:03<00:14, 19.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 fire hydrant, 1 backpack, 7 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 fire hydrant, 1 backpack, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|‚ñà‚ñç        | 49/331 [00:03<00:14, 19.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 fire hydrant, 1 backpack, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|‚ñà‚ñå        | 52/331 [00:03<00:14, 19.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|‚ñà‚ñã        | 54/331 [00:03<00:14, 19.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 10.3ms\n",
            "Speed: 1.8ms preprocess, 10.3ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|‚ñà‚ñã        | 56/331 [00:03<00:14, 19.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 13.8ms\n",
            "Speed: 2.0ms preprocess, 13.8ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 8 handbags, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|‚ñà‚ñä        | 58/331 [00:04<00:16, 16.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 11.4ms\n",
            "Speed: 5.2ms preprocess, 11.4ms inference, 25.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 backpack, 6 handbags, 1 bottle, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 35.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|‚ñà‚ñä        | 60/331 [00:04<00:17, 15.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 19.9ms\n",
            "Speed: 4.0ms preprocess, 19.9ms inference, 29.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 23.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|‚ñà‚ñä        | 62/331 [00:04<00:19, 13.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 6 handbags, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 27.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|‚ñà‚ñâ        | 64/331 [00:04<00:20, 12.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 26.4ms\n",
            "Speed: 4.0ms preprocess, 26.4ms inference, 39.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|‚ñà‚ñâ        | 66/331 [00:04<00:20, 12.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|‚ñà‚ñà        | 68/331 [00:04<00:18, 13.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|‚ñà‚ñà        | 70/331 [00:04<00:17, 15.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|‚ñà‚ñà‚ñè       | 72/331 [00:05<00:16, 16.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|‚ñà‚ñà‚ñè       | 74/331 [00:05<00:15, 16.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 4 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|‚ñà‚ñà‚ñé       | 76/331 [00:05<00:14, 17.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 4 backpacks, 4 handbags, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 27.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|‚ñà‚ñà‚ñé       | 78/331 [00:05<00:14, 16.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 6 handbags, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|‚ñà‚ñà‚ñç       | 80/331 [00:05<00:14, 17.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|‚ñà‚ñà‚ñç       | 82/331 [00:05<00:13, 17.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|‚ñà‚ñà‚ñå       | 84/331 [00:05<00:13, 18.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 19.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|‚ñà‚ñà‚ñå       | 86/331 [00:05<00:13, 18.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 8 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|‚ñà‚ñà‚ñã       | 88/331 [00:05<00:13, 18.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 backpacks, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|‚ñà‚ñà‚ñã       | 90/331 [00:06<00:13, 18.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|‚ñà‚ñà‚ñä       | 92/331 [00:06<00:12, 18.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|‚ñà‚ñà‚ñä       | 95/331 [00:06<00:12, 19.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|‚ñà‚ñà‚ñâ       | 97/331 [00:06<00:12, 19.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|‚ñà‚ñà‚ñà       | 100/331 [00:06<00:11, 19.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|‚ñà‚ñà‚ñà       | 102/331 [00:06<00:11, 19.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|‚ñà‚ñà‚ñà‚ñè      | 104/331 [00:06<00:11, 19.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|‚ñà‚ñà‚ñà‚ñè      | 107/331 [00:06<00:11, 20.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|‚ñà‚ñà‚ñà‚ñé      | 110/331 [00:07<00:10, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 5 handbags, 2 suitcases, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|‚ñà‚ñà‚ñà‚ñç      | 113/331 [00:07<00:10, 20.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|‚ñà‚ñà‚ñà‚ñå      | 116/331 [00:07<00:10, 20.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 23.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 16.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 23.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|‚ñà‚ñà‚ñà‚ñå      | 119/331 [00:07<00:11, 18.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 2 suitcases, 19.2ms\n",
            "Speed: 3.9ms preprocess, 19.2ms inference, 26.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 suitcase, 11.7ms\n",
            "Speed: 2.0ms preprocess, 11.7ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|‚ñà‚ñà‚ñà‚ñã      | 121/331 [00:07<00:12, 17.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 1 suitcase, 13.6ms\n",
            "Speed: 1.8ms preprocess, 13.6ms inference, 21.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|‚ñà‚ñà‚ñà‚ñã      | 123/331 [00:07<00:12, 16.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 24.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|‚ñà‚ñà‚ñà‚ñä      | 125/331 [00:07<00:12, 15.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|‚ñà‚ñà‚ñà‚ñä      | 127/331 [00:08<00:12, 15.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 19.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|‚ñà‚ñà‚ñà‚ñâ      | 129/331 [00:08<00:13, 15.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 20.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 11.5ms\n",
            "Speed: 1.9ms preprocess, 11.5ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|‚ñà‚ñà‚ñà‚ñâ      | 131/331 [00:08<00:13, 15.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|‚ñà‚ñà‚ñà‚ñà      | 133/331 [00:08<00:13, 15.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.7ms\n",
            "Speed: 2.7ms preprocess, 10.7ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|‚ñà‚ñà‚ñà‚ñà      | 135/331 [00:08<00:12, 15.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 137/331 [00:08<00:12, 15.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 139/331 [00:08<00:12, 15.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 handbags, 1 suitcase, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 4.1ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 141/331 [00:08<00:11, 16.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 handbags, 1 suitcase, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 22.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 24.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 143/331 [00:09<00:12, 15.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 23.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 5.6ms preprocess, 10.1ms inference, 21.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 145/331 [00:09<00:12, 15.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.8ms preprocess, 10.0ms inference, 19.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 1 suitcase, 11.4ms\n",
            "Speed: 4.1ms preprocess, 11.4ms inference, 26.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 147/331 [00:09<00:12, 14.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 149/331 [00:09<00:12, 14.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 5 handbags, 2 suitcases, 17.5ms\n",
            "Speed: 6.0ms preprocess, 17.5ms inference, 22.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 10.9ms\n",
            "Speed: 4.6ms preprocess, 10.9ms inference, 22.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 151/331 [00:09<00:13, 13.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 2 suitcases, 18.8ms\n",
            "Speed: 3.5ms preprocess, 18.8ms inference, 22.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 153/331 [00:09<00:12, 14.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 5 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 155/331 [00:09<00:11, 15.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 6 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 157/331 [00:10<00:10, 16.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 160/331 [00:10<00:09, 18.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 163/331 [00:10<00:08, 19.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 166/331 [00:10<00:08, 20.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 9 persons, 4 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 169/331 [00:10<00:08, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 172/331 [00:10<00:07, 19.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 174/331 [00:10<00:07, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 horse, 1 backpack, 2 handbags, 2 suitcases, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 176/331 [00:10<00:07, 19.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 horse, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 horse, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 178/331 [00:11<00:08, 17.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 40.4ms\n",
            "Speed: 8.0ms preprocess, 40.4ms inference, 71.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 180/331 [00:11<00:11, 13.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 16.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 182/331 [00:11<00:10, 14.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 1 backpack, 4 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 184/331 [00:11<00:09, 14.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 186/331 [00:11<00:08, 16.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 5 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 189/331 [00:11<00:08, 17.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 28.0ms\n",
            "Speed: 1.9ms preprocess, 28.0ms inference, 53.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 5 handbags, 1 suitcase, 24.3ms\n",
            "Speed: 8.0ms preprocess, 24.3ms inference, 47.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 191/331 [00:12<00:11, 12.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 3 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 194/331 [00:12<00:09, 14.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 197/331 [00:12<00:08, 16.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 200/331 [00:12<00:07, 17.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 2 suitcases, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 202/331 [00:12<00:07, 17.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 handbags, 2 suitcases, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 2 suitcases, 26.4ms\n",
            "Speed: 5.8ms preprocess, 26.4ms inference, 88.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 204/331 [00:12<00:09, 14.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 28.1ms\n",
            "Speed: 5.9ms preprocess, 28.1ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 206/331 [00:13<00:08, 14.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 208/331 [00:13<00:08, 15.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 4 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 210/331 [00:13<00:07, 16.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 213/331 [00:13<00:06, 17.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 215/331 [00:13<00:06, 18.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 217/331 [00:13<00:06, 18.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 3 handbags, 2 suitcases, 11.2ms\n",
            "Speed: 1.8ms preprocess, 11.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 219/331 [00:13<00:06, 18.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 15.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 222/331 [00:13<00:05, 19.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 suitcases, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 224/331 [00:13<00:05, 19.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 5 handbags, 2 suitcases, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 227/331 [00:14<00:05, 19.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 car, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 229/331 [00:14<00:05, 19.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 231/331 [00:14<00:05, 19.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 16 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 233/331 [00:14<00:04, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 235/331 [00:14<00:04, 19.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 237/331 [00:14<00:04, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 26.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 239/331 [00:14<00:04, 18.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 241/331 [00:14<00:04, 19.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 243/331 [00:14<00:04, 19.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 14.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 246/331 [00:15<00:04, 19.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 3 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 3 backpacks, 4 handbags, 1 suitcase, 11.9ms\n",
            "Speed: 1.9ms preprocess, 11.9ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 248/331 [00:15<00:04, 19.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 250/331 [00:15<00:04, 18.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 6 handbags, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 16.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 252/331 [00:15<00:04, 18.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 2 backpacks, 7 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 7 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 254/331 [00:15<00:04, 19.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 257/331 [00:15<00:03, 19.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 259/331 [00:15<00:03, 19.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 261/331 [00:15<00:03, 19.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 15 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 14.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 263/331 [00:15<00:03, 19.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 11.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 266/331 [00:16<00:03, 19.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 5 handbags, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 269/331 [00:16<00:03, 20.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 272/331 [00:16<00:02, 20.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 6 handbags, 2 suitcases, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 275/331 [00:16<00:02, 20.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 5 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 11.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 278/331 [00:16<00:02, 20.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 18.1ms\n",
            "Speed: 2.5ms preprocess, 18.1ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 281/331 [00:16<00:02, 19.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 2 handbags, 2 suitcases, 1 bottle, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 283/331 [00:16<00:02, 19.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 2 suitcases, 1 cell phone, 10.0ms\n",
            "Speed: 1.7ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 285/331 [00:17<00:02, 19.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 287/331 [00:17<00:02, 19.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 289/331 [00:17<00:02, 19.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 4 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 292/331 [00:17<00:01, 19.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 11.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 295/331 [00:17<00:01, 20.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 1 handbag, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 4 handbags, 1 cell phone, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 298/331 [00:17<00:01, 19.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 10 persons, 1 backpack, 2 handbags, 1 cell phone, 10.7ms\n",
            "Speed: 1.8ms preprocess, 10.7ms inference, 24.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 300/331 [00:17<00:01, 19.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.5ms\n",
            "Speed: 1.9ms preprocess, 10.5ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 303/331 [00:17<00:01, 19.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 4 handbags, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 16.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 305/331 [00:18<00:01, 19.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 2 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 308/331 [00:18<00:01, 20.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 11 persons, 1 backpack, 3 handbags, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 3 handbags, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 311/331 [00:18<00:00, 20.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 10 persons, 2 backpacks, 6 handbags, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 5 handbags, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 314/331 [00:18<00:00, 20.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 8 persons, 1 backpack, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 8 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 317/331 [00:18<00:00, 20.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 3 handbags, 2 suitcases, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 3 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 16.8ms\n",
            "Speed: 1.9ms preprocess, 16.8ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 320/331 [00:18<00:00, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 14 persons, 2 backpacks, 2 handbags, 1 suitcase, 11.5ms\n",
            "Speed: 3.9ms preprocess, 11.5ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 322/331 [00:18<00:00, 19.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 324/331 [00:19<00:00, 19.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 12 persons, 1 backpack, 1 handbag, 2 suitcases, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 14.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 326/331 [00:19<00:00, 19.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 13 persons, 1 backpack, 1 handbag, 1 suitcase, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 backpack, 2 handbags, 1 suitcase, 10.0ms\n",
            "Speed: 1.5ms preprocess, 10.0ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 331/331 [00:19<00:00, 17.16it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iax_ZdK-L-Q1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}